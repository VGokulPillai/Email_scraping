{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b21039e4-8aed-42ce-beaf-6907e95fe7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawled Main URL: https://www.fruitandveg.co.uk/\n",
      "Crawled Contact URL: https://www.fruitandveg.co.uk/contact-us/\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.fruitandveg.co.uk/\",\n",
      " \"Email_contact\": \"info@fruitandveg.co.uk\"\n",
      "}\n",
      "Crawled Main URL: https://www.munneries.co.uk/\n",
      "Crawled Contact URL: https://www.munneries.co.uk/contact-us/\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.munneries.co.uk/\",\n",
      " \"Email_contact\": \"info@munneries.co.uk\"\n",
      "}\n",
      "Crawled Main URL: https://eurofrutta.co.uk/\n",
      "Crawled Contact URL: https://eurofrutta.co.uk/contact/\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://eurofrutta.co.uk/\",\n",
      " \"Email_contact\": \"sales@eurofrutta.co.uk\"\n",
      "}\n",
      "Crawled Main URL: https://www.wattsfarms.co.uk/\n",
      "Crawled Contact URL: https://www.wattsfarms.co.uk/contact-us/\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.wattsfarms.co.uk/\",\n",
      " \"Email_contact\": \"sales@wattsfarms.co.uk\"\n",
      "}\n",
      "Crawled Main URL: https://www.potgang.co.uk/\n",
      "Crawled Contact URL: https://www.potgang.co.uk/pages/contact-us\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.potgang.co.uk/\",\n",
      " \"Email_contact\": \"sam@potgang.co.uk\"\n",
      "}\n",
      "Crawled Main URL: https://www.alexandrarose.org.uk/\n",
      "Crawled Contact URL: https://www.alexandrarose.org.uk/contact/\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.alexandrarose.org.uk/\",\n",
      " \"Email_contact\": \"info@alexandrarose.org.uk\"\n",
      "}\n",
      "Crawled Main URL: https://www.riverford.co.uk/\n",
      "Crawled Contact URL: https://www.riverford.co.uk/help\n",
      "\n",
      "\n",
      " {\n",
      " \"Websites\": \"https://www.riverford.co.uk/\",\n",
      " \"Email_contact\": \"help@riverford.co.uk\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "#Website url link\n",
    "urls = ''\n",
    "\n",
    "#loading the website url from supplier.txt file\n",
    "with open('suppliers.txt','r') as i:\n",
    "    for lines in i.read():\n",
    "        urls+=lines\n",
    "\n",
    "#converting it into list        \n",
    "urls = list(filter(None,urls.split('\\n')))\n",
    "\n",
    "\n",
    "#dict \n",
    "contacts = {}\n",
    "\n",
    "#stack\n",
    "e_mail=[]\n",
    "Web_site =[]\n",
    "\n",
    "#hash_map\n",
    "hash_map={}\n",
    "\n",
    "#loop over url\n",
    "for url in urls:\n",
    "    \n",
    "    #parse response \n",
    "    res = requests.get(url)\n",
    "    \n",
    "    #crawling the main url \n",
    "    print('Crawled Main URL:',res.url)\n",
    "    \n",
    "    #taking the content from it \n",
    "    content = BeautifulSoup(res.text,'lxml')\n",
    "    \n",
    "    \n",
    "    #dict is build for accessing it \n",
    "    contacts = {\n",
    "        'Websites':res.url,\n",
    "        'Email_contact':'',\n",
    "        \n",
    "    }\n",
    "    \n",
    "    Web_site.append(res.url)\n",
    "    \n",
    "    #Extracting the contact link\n",
    "    try:\n",
    "        contact = content.find('a',text=re.compile('contact',re.IGNORECASE))['href']\n",
    "        if 'http' in contact:\n",
    "            contact_url = contact\n",
    "        else:\n",
    "            contact_url = res.url[0:-1] + contact\n",
    "\n",
    "        res_contact = requests.get(contact_url)\n",
    "        contact_content = BeautifulSoup(res_contact.text,'lxml').get_text()\n",
    "        \n",
    "        #crawling into the contact details of the website\n",
    "        print('Crawled Contact URL:',res_contact.url)\n",
    "        \n",
    "        #email is made into set to avoid repeatition and same index for a unique mail_id\n",
    "        email = set(re.findall('(\\w+@\\w+\\.\\w+\\.\\w+)',contact_content))\n",
    "        \n",
    "        contacts['Email_contact'] = ', '.join(email)\n",
    "        e_mail.append(email)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    #Hash_map will store value for website and email id \n",
    "    #set key as website so if want to access to any kind of email_ids\n",
    "    for i in Web_site:\n",
    "        for j in e_mail:\n",
    "            hash_map[i]=j\n",
    "            \n",
    "        \n",
    "    #print the result \n",
    "    print('\\n\\n',json.dumps(contacts, indent=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a3dd06-b2a8-48d2-a32d-7b196ea829e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
